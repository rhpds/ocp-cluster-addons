# This is an example of a 3scale API configuration for LLMs.
# It includes project/domain specific details, so it should be located
# in the repository of the project that uses/calls this helm chart.
# See application-3scale-sources.yml on how to specify an external values.yaml file.

# https://github.com/3scale/3scale-operator/blob/master/doc/product-reference.md
apis:
  - name: granite-8b-code-instruct
    activeDocOpenAPIRef: https://raw.githubusercontent.com/redhat-gpte-devopsautomation/llm-aas/refs/heads/main/bootstrap/3scale/api_definitions/granite-8b-code-instruct.json
    backend:
      privateBaseURL: http://granite-8b-code-instruct-128k-predictor.llm-hosting.svc.cluster.local:8080
      path: /
    deployment:
      apicastHosted:
        authentication:
          userkey:
            authUserKey: Authorization
            credentials: authorization
    policies:
      - name: cors
        enabled: true
        version: builtin
        configuration:
          allow_headers: ["Authorization", "Content-type", "Accept"]
          allow_methods: []
          allow_origin: "*"
      - name: upstream_connection
        enabled: true
        version: builtin
        configuration:
          connect_timeout: 300
          send_timeout: 300
          read_timeout: 300
      - name: llm-metrics
        enabled: true
        version: "0.1"
        configuration:
          enable_sse_support: true
          rules:
          - condition:
              combine_op: and
              operations:
              - left: "{{status}}"
                left_type: liquid
                op: "=="
                right: '200'
                right_type: plain
            increment: "{{ llm_usage.total_tokens }}"
            metric: total_tokens
          - condition:
              combine_op: and
              operations:
              - left: "{{status}}"
                left_type: liquid
                op: "=="
                right: '200'
                right_type: plain
            increment: "{{ llm_usage.prompt_tokens }}"
            metric: prompt_tokens
          - condition:
              combine_op: and
              operations:
              - left: "{{status}}"
                left_type: liquid
                op: "=="
                right: '200'
                right_type: plain
            increment: "{{ llm_usage.completion_tokens }}"
            metric: completion_tokens
      - name: apicast
        enabled: true
        version: builtin
        configuration: {}
    metrics:
      hits:
        friendlyName: Hits
        unit: hit
        description: Number of API hits
      completion_tokens:
        friendlyName: Completion Tokens
        unit: token
        description: Number of completion tokens
      prompt_tokens:
        friendlyName: Prompt Tokens
        unit: token
        description: Number of prompt tokens
      total_tokens:
        friendlyName: Total Tokens
        unit: token
        description: Number of total tokens
    methods:
      health:
        friendlyName: Health
      tokenize:
        friendlyName: Tokenize
      detokenize:
        friendlyName: Detokenize
      models:
        friendlyName: Models
      version:
        friendlyName: Version
      chat/completions:
        friendlyName: Chat Completions
      completions:
        friendlyName: Completions
      embeddings:
        friendlyName: Embeddings
    mappingRules:
      - httpMethod: GET
        pattern: "/health"
        metricMethodRef: health
        increment: 1
      - httpMethod: POST
        pattern: "/tokenize"
        metricMethodRef: tokenize
        increment: 1
      - httpMethod: POST
        pattern: "/detokenize"
        metricMethodRef: detokenize
        increment: 1
      - httpMethod: GET
        pattern: "/v1/models"
        metricMethodRef: models
        increment: 1
      - httpMethod: GET
        pattern: "/version"
        metricMethodRef: version
        increment: 1
      - httpMethod: POST
        pattern: "/v1/chat/completions"
        metricMethodRef: chat/completions
        increment: 1
      - httpMethod: POST
        pattern: "/v1/completions"
        metricMethodRef: completions
        increment: 1
      - httpMethod: POST
        pattern: "/v1/embeddings"
        metricMethodRef: embeddings
        increment: 1
    applicationPlans:
      standard:
        name: "Standard Plan"
        appsRequireApproval: "false"
        published: "true"
  - name: mistral-7b-instruct-v0-3
    activeDocOpenAPIRef: https://raw.githubusercontent.com/redhat-gpte-devopsautomation/llm-aas/refs/heads/main/bootstrap/3scale/api_definitions/mistral-7b-instruct-v0.3.json
    backend:
      privateBaseURL: http://mistral-7b-instruct-predictor.llm-hosting.svc.cluster.local:8080
      path: /
    deployment:
      apicastHosted:
        authentication:
          userkey:
            authUserKey: Authorization
            credentials: headers
    policies:
      - name: cors
        enabled: true
        version: builtin
        configuration:
          allow_headers: ["Authorization", "Content-type", "Accept"]
          allow_methods: []
          allow_origin: "*"
      - name: upstream_connection
        enabled: true
        version: builtin
        configuration:
          connect_timeout: 300
          send_timeout: 300
          read_timeout: 300
      - name: llm-metrics
        enabled: true
        version: "0.1"
        configuration:
          enable_sse_support: true
          rules:
          - condition:
              combine_op: and
              operations:
              - left: "{{status}}"
                left_type: liquid
                op: "=="
                right: '200'
                right_type: plain
            increment: "{{ llm_usage.total_tokens }}"
            metric: total_tokens
          - condition:
              combine_op: and
              operations:
              - left: "{{status}}"
                left_type: liquid
                op: "=="
                right: '200'
                right_type: plain
            increment: "{{ llm_usage.prompt_tokens }}"
            metric: prompt_tokens
          - condition:
              combine_op: and
              operations:
              - left: "{{status}}"
                left_type: liquid
                op: "=="
                right: '200'
                right_type: plain
            increment: "{{ llm_usage.completion_tokens }}"
            metric: completion_tokens
      - name: apicast
        enabled: true
        version: builtin
        configuration: {}
    metrics:
      hits:
        friendlyName: Hits
        unit: hit
        description: Number of API hits
      completion_tokens:
        friendlyName: Completion Tokens
        unit: token
        description: Number of completion tokens
      prompt_tokens:
        friendlyName: Prompt Tokens
        unit: token
        description: Number of prompt tokens
      total_tokens:
        friendlyName: Total Tokens
        unit: token
        description: Number of total tokens
    methods:
      health:
        friendlyName: Health
      tokenize:
        friendlyName: Tokenize
      detokenize:
        friendlyName: Detokenize
      models:
        friendlyName: Models
      version:
        friendlyName: Version
      chat/completions:
        friendlyName: Chat Completions
      completions:
        friendlyName: Completions
      embeddings:
        friendlyName: Embeddings
    mappingRules:
      - httpMethod: GET
        pattern: "/health"
        metricMethodRef: health
        increment: 1
      - httpMethod: POST
        pattern: "/tokenize"
        metricMethodRef: tokenize
        increment: 1
      - httpMethod: POST
        pattern: "/detokenize"
        metricMethodRef: detokenize
        increment: 1
      - httpMethod: GET
        pattern: "/v1/models"
        metricMethodRef: models
        increment: 1
      - httpMethod: GET
        pattern: "/version"
        metricMethodRef: version
        increment: 1
      - httpMethod: POST
        pattern: "/v1/chat/completions"
        metricMethodRef: chat/completions
        increment: 1
      - httpMethod: POST
        pattern: "/v1/completions"
        metricMethodRef: completions
        increment: 1
      - httpMethod: POST
        pattern: "/v1/embeddings"
        metricMethodRef: embeddings
        increment: 1
    applicationPlans:
      standard:
        name: "Standard Plan"
        appsRequireApproval: "false"
        published: "true"
  # - name: other
  #   activeDocOpenAPIRef: https://unknown/openapi.json
